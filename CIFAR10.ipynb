{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model #save and load models\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (60000, 32, 32, 3)\n",
      "y shape: (60000, 1)\n",
      "y1 shape (60000, 10)\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "#combining all the available data to use it in a way we want\n",
    "x = np.vstack((X_train,X_test))\n",
    "y = np.vstack((Y_train,Y_test))\n",
    "print('x shape:', x.shape)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "x = x.astype('float32')\n",
    "x = x/255\n",
    "num_classes = 10\n",
    "y1 = keras.utils.to_categorical(y, num_classes)\n",
    "print('y1 shape', y1.shape)\n",
    "print('Number of classes:', y1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters for target and shadow models\n",
    "batch_size = 32 #upto us\n",
    "epochs = 100\n",
    "lrate = 0.001\n",
    "decay = 1e-7 #find out what this decay parameter does\n",
    "kernel_size = (5,5) #upto us\n",
    "kernel_size2 = (3,3) #upto us\n",
    "nout1 = 32 #upto us\n",
    "nout2 = 32 #upto us\n",
    "ndense = 128\n",
    "#initializer in each layer - upto us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target model summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 160,554\n",
      "Trainable params: 160,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "For target model with ds = 2500\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.457600\n",
      "Shadow model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 160,554\n",
      "Trainable params: 160,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "For shadow model 0\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.471200\n",
      "\n",
      "For shadow model 1\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.463600\n",
      "\n",
      "For shadow model 2\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.458400\n",
      "\n",
      "For shadow model 3\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.481200\n",
      "\n",
      "For shadow model 4\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.460400\n",
      "\n",
      "For shadow model 5\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.480000\n",
      "\n",
      "For shadow model 6\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.476800\n",
      "\n",
      "For shadow model 7\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.473200\n",
      "\n",
      "For shadow model 8\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.486800\n",
      "\n",
      "For shadow model 9\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.490800\n",
      "\n",
      "\n",
      "For target model with ds = 5000\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.521600\n",
      "\n",
      "For shadow model 0\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.497000\n",
      "\n",
      "For shadow model 1\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.536000\n",
      "\n",
      "For shadow model 2\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.519600\n",
      "\n",
      "For shadow model 3\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.521200\n",
      "\n",
      "For shadow model 4\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.521000\n",
      "\n",
      "For shadow model 5\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.532000\n",
      "\n",
      "For shadow model 6\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.520200\n",
      "\n",
      "For shadow model 7\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.528800\n",
      "\n",
      "For shadow model 8\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.524800\n",
      "\n",
      "For shadow model 9\n",
      "Training accuracy = 1.000000\n",
      "Validation accuracy = 0.518400\n"
     ]
    }
   ],
   "source": [
    "data_size = [2500,5000] #[2500,5000,10000,15000]\n",
    "target_rep = np.zeros((len(data_size),x.shape[0]))\n",
    "ns = 10 #number of shadow models for one data_size\n",
    "\n",
    "for i,ds in enumerate(data_size): \n",
    "    sh = np.arange(x.shape[0])\n",
    "    np.random.shuffle(sh)\n",
    "    target_rep[i,:] = sh\n",
    "    xtr_target = x[sh[:ds]]\n",
    "    ytr_target = y1[sh[:ds]]\n",
    "    xts_target = x[sh[ds:2*ds]]\n",
    "    yts_target = y1[sh[ds:2*ds]]\n",
    "    shadow_rep = np.zeros((ns,x.shape[0]-2*ds))\n",
    "    sh2 = sh[2*ds:]\n",
    "    \n",
    "    #Training the target model when size of train & test data = ds\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(nout1, kernel_size, \n",
    "                     padding='valid', \n",
    "                     input_shape=xtr_target.shape[1:],\n",
    "                     activation='tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(nout2, kernel_size2, padding='valid', activation='tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(ndense, activation='tanh'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # initiate Adam optimizer\n",
    "    opt = keras.optimizers.adam(lr=lrate, decay=decay)\n",
    "\n",
    "    # Let's train the model using Adam\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    #print model summary just once\n",
    "    if i == 0:\n",
    "        print('Target model summary')\n",
    "        print(model.summary())\n",
    "    # Fit the model\n",
    "    #put verbose = 0 when actually running\n",
    "    hist_target = model.fit(xtr_target, ytr_target,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(xts_target, yts_target),\n",
    "                  shuffle=True,verbose=0)\n",
    "    print('\\n\\nFor target model with ds = %d'%ds)\n",
    "    print('Training accuracy = %f'%hist_target.history['acc'][-1])\n",
    "    print('Validation accuracy = %f'%hist_target.history['val_acc'][-1])\n",
    "    model_name = 'cifar10_target_'+str(ds)+'.h5'\n",
    "    model.save(model_name)\n",
    "    ytemp1 = model.predict(xtr_target)\n",
    "    ytemp2 = model.predict(xts_target)\n",
    "    xts_att = np.vstack((ytemp1,ytemp2))\n",
    "    yts_att = np.zeros(2*ds)\n",
    "    yts_att[:ds] = 1 \n",
    "    xts_att_truelabels = np.vstack((ytr_target,yts_target))\n",
    "    xts_att_dict = {'xts_att':xts_att,'yts_att':yts_att,'xts_att_truelabels':xts_att_truelabels}\n",
    "    fname = './att_test_data_'+str(ds)\n",
    "    np.save(fname,xts_att_dict)\n",
    "    \n",
    "    xtr_att = np.zeros((2*ds*ns,num_classes))\n",
    "    ytr_att = np.zeros((2*ds*ns,))\n",
    "    xtr_att_truelabels = np.zeros((2*ds*ns,num_classes))\n",
    "    for j in np.arange(ns):\n",
    "        np.random.shuffle(sh2)\n",
    "        shadow_rep[j,:] = sh2\n",
    "        xtr_sh1 = x[sh2[:ds]]\n",
    "        ytr_sh1 = y1[sh2[:ds]]\n",
    "        xts_sh1 = x[sh2[ds:2*ds]]\n",
    "        yts_sh1 = y1[sh2[ds:2*ds]]\n",
    "        \n",
    "        model_sh1 = Sequential()\n",
    "        model_sh1.add(Conv2D(nout1, kernel_size, \n",
    "                         padding='valid', \n",
    "                         input_shape=xtr_sh1.shape[1:],\n",
    "                         activation='tanh'))\n",
    "        model_sh1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model_sh1.add(Conv2D(nout2, kernel_size2, padding='valid', activation='tanh'))\n",
    "        model_sh1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model_sh1.add(Flatten())\n",
    "        model_sh1.add(Dense(ndense, activation='tanh'))\n",
    "        model_sh1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        # initiate Adam optimizer\n",
    "        opt_sh1 = keras.optimizers.adam(lr=lrate, decay=decay)\n",
    "\n",
    "        # Let's train the model using Adam\n",
    "        model_sh1.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=opt_sh1,\n",
    "                          metrics=['accuracy'])\n",
    "        if j == 0 and i==0:\n",
    "            print('Shadow model summary:')\n",
    "            print(model_sh1.summary())\n",
    "        hist_sh1 = model_sh1.fit(xtr_sh1, ytr_sh1,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(xts_sh1, yts_sh1),\n",
    "                  shuffle=True,verbose=0)\n",
    "        model_name = 'cifar10_shadow_'+str(ds)+'_'+str(j)+'.h5'\n",
    "        model_sh1.save(model_name)\n",
    "        print('\\nFor shadow model %d'%j)\n",
    "        print('Training accuracy = %f'%hist_sh1.history['acc'][-1])\n",
    "        print('Validation accuracy = %f'%hist_sh1.history['val_acc'][-1])\n",
    "        ytemp11 = model_sh1.predict(xtr_sh1)\n",
    "        ytemp22 = model_sh1.predict(xts_sh1)\n",
    "        xtr_att[j*2*ds:(j+1)*2*ds] = np.vstack((ytemp11,ytemp22))\n",
    "        ytr_att[j*2*ds:(2*j+1)*ds] = 1\n",
    "        xtr_att_truelabels[j*2*ds:(j+1)*2*ds] = np.vstack((ytr_sh1,yts_sh1))\n",
    "    \n",
    "    #in outer for loop now\n",
    "    datafile = './data_cifar10_shadow_'+str(ds)\n",
    "    np.save(datafile,shadow_rep)\n",
    "    xtr_att_dict = {'xtr_att':xtr_att,'ytr_att':ytr_att,'xtr_att_truelabels':xtr_att_truelabels}\n",
    "    fname = './att_train_data_'+str(ds)\n",
    "    np.save(fname,xtr_att_dict)\n",
    "#outside both for loops\n",
    "np.save('./data_cifar10_target',target_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
